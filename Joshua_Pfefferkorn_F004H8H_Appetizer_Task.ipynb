{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appetizer Task: Hand-Written Digit Classification with Least-Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Do not change the code here\n",
    "from matplotlib.pyplot import plot\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appetizer Task\n",
    "Please read the Appetizer section in the pdf file for the project requirement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Do not change the code here\n",
    "train_data_path = \"MNIST_Sub/\" + \"train_data.txt\"\n",
    "train_labels_path = \"MNIST_Sub/\" + \"train_labels.txt\"\n",
    "test_data_path = \"MNIST_Sub/\" + \"test_data.txt\"\n",
    "test_labels_path = \"MNIST_Sub/\" + \"test_labels.txt\"\n",
    "\n",
    "### the dataset class is provided ###\n",
    "class Dataset:\n",
    "    def __init__(self, train_data_path, train_labels_path, test_data_path, test_labels_path):\n",
    "        self.train_data_path = train_data_path\n",
    "        self.train_labels_path = train_labels_path\n",
    "        self.test_data_path = test_data_path\n",
    "        self.test_labels_path = test_labels_path\n",
    "        \n",
    "        self.train_data = []\n",
    "        self.train_labels = []\n",
    "        self.test_data = []\n",
    "        self.test_labels = []\n",
    "\n",
    "    def dataloader(self,):\n",
    "            '''\n",
    "            The shape of train data should be (n_samples,28^2)\n",
    "            '''\n",
    "            with open(self.train_data_path, \"r\") as f:\n",
    "                for line in f:\n",
    "                    self.train_data.append(np.array(line.strip().split()).astype(np.float64)/255.0)\n",
    "                self.train_data = np.array(self.train_data)\n",
    "\n",
    "            with open(self.train_labels_path, \"r\") as f:\n",
    "                for line in f:\n",
    "                    self.train_labels.append(int(line.strip()))\n",
    "                self.train_labels = np.array(self.train_labels)\n",
    "                \n",
    "\n",
    "            with open(self.test_data_path, \"r\") as f:\n",
    "                for line in f:\n",
    "                    self.test_data.append(np.array(line.strip().split()).astype(np.float64)/255.0)\n",
    "                self.test_data = np.array(self.test_data)\n",
    "                \n",
    "\n",
    "            with open(self.test_labels_path, \"r\") as f:\n",
    "                for line in f:\n",
    "                    self.test_labels.append(int(line.strip()))\n",
    "                self.test_labels = np.array(self.test_labels)\n",
    "                \n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "###TODO: implement your functions, don't change input \n",
    "\n",
    "#add a bias column to x \n",
    "def add_bias_column(x):\n",
    "    bias = np.ones([x.shape[0], 1])\n",
    "    return np.concatenate((x,bias), 1)\n",
    "\n",
    "###the main function for solving theta, refer to the project requirement\n",
    "def classifier(x, y, classes=10):\n",
    "    #x: train_data\n",
    "    #y: train_labels\n",
    "    #classes: # of classes\n",
    "   \n",
    "    x = add_bias_column(x)\n",
    "    theta = np.zeros([x.shape[1], classes])\n",
    "    \n",
    "    ### add random noise to training data\n",
    "    \n",
    "    # loop over entire x\n",
    "    for i in range(0, x.shape[0]):\n",
    "        for j in range(0, x.shape[1]):\n",
    "            # add a value from 0 to 0.0001, randomly, to each index of x\n",
    "            x[i,j] += np.random.uniform(0,0.0001)\n",
    "            \n",
    "            # NOTE: the project details said to choose noise from 0.001, \n",
    "            # but I chose to scale that down slightly as Prof. Zhu suggested in the Slack\n",
    "            # to avoid too much variance in accuracies between runs\n",
    "            \n",
    "    ### build Y (a 1000x10 matrix of 1s and -1s) based on training labels\n",
    "    \n",
    "    # initialize Y as a 1000 x 10 matrix of -1s\n",
    "    Y = np.ones((x.shape[0], classes))*-1\n",
    "    # for each row, change the value in the correct column to 1 based on training labels \n",
    "    for m in range(0,x.shape[0]):\n",
    "        Y[m,y[m]] = 1\n",
    "    \n",
    "    ### solve 10 LS problems\n",
    "    \n",
    "    # for each column of Y\n",
    "    for k in range (0, classes):\n",
    "        Y_col = Y[:,k]\n",
    "        # solve normal equations x^TxW = x^TY\n",
    "        w_column = np.linalg.solve(x.T @ x,  x.T @ Y_col)\n",
    "        # insert solved column of W into theta\n",
    "        theta[:,k] = np.copy(w_column)\n",
    "    \n",
    "    return theta\n",
    "    \n",
    "#evaluate your solution on test data\n",
    "def evaluate(x, y, theta):\n",
    "    x = add_bias_column(x)\n",
    "    y_pred = np.matmul(x, theta)\n",
    "    y_pred = np.argmax(y_pred, 1)\n",
    "    accuracy = (y_pred == y).mean()\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of training samples: 1000\n",
      "# of testing samples: 200\n"
     ]
    }
   ],
   "source": [
    "###Do not change the code###\n",
    "###load data###\n",
    "data = Dataset(train_data_path, train_labels_path, test_data_path, test_labels_path)\n",
    "data.dataloader()\n",
    "x_train, y_train, x_test, y_test = data.train_data, data.train_labels, data.test_data, data.test_labels\n",
    "print(\"# of training samples:\", x_train.shape[0])\n",
    "print(\"# of testing samples:\", x_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy is: 0.765\n",
      "Testing accuracy is: 0.43\n"
     ]
    }
   ],
   "source": [
    "###Run your code and print out the test accuracy\n",
    "\n",
    "theta = classifier(x_train, y_train) ###solve Theta\n",
    "training_accuracy=evaluate(x_train, y_train, theta)\n",
    "print(\"Training accuracy is:\", training_accuracy)\n",
    "\n",
    "testing_accuracy = evaluate(x_test, y_test, theta) ###test \n",
    "print(\"Testing accuracy is:\", testing_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
